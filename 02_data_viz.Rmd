---
title: "TS_FinalProject_Results_Dataviz"
author: "Mark Roberts"
date: "6/5/2020"
output: html_document
---
importing libraries
```{r}
library(wesanderson)
library(reshape2)
library(ggthemes)
```

creating palette
```{r}
pallette_name <- "Royal1"
single_color <- "#660000"

two_colors <- wes_palette(pallette_name, n = 2)
four_colors <- wes_palette(pallette_name, n = 4)
pal <- wes_palette("Royal1", 20, type = "continuous")
pal
```
```{r}
for (i in pal) {
  print(i)
}
```
```{r, echo=FALSE}
#1 Holt-winters
#2 STL
#3 Prophet
   
#1 building Holt Winters model- weekly data only
Holt_Winters_model <- function(train_series_daily, test_series_daily, train_series_weekly, test_series_weekly, item_names, category_names){
  #packages
  library(forecast)
  library(Metrics)
  #initializing vectors
  product <- item_names
  method <- rep("Holt_Winters", length(train_series_daily))
  seasonality <- c()
  test_mase <- c()
  Ljung_Box_p_value <- c()
  AIC <- c()
  category <- c()
  
  #no daily data
  
  #weekly data 
  for (i in seq_along(train_series_weekly)){
    model_weekly <- suppressWarnings(HoltWinters(ts(train_series_daily[[i]], frequency = 7), seasonal = 'additive'))
    forecast_weekly <- forecast(model_weekly, h = 28)
    mase_weekly <- mase(as.numeric(test_series_weekly[[i]]), as.numeric(forecast_weekly$mean))
    res_weekly <- residuals(forecast_weekly)
    lb_weekly <- Box.test(res_weekly, lag=14, type = "Lj")$p.value
    AIC_weekly <- NA #AIC(model_weekly)
    #storing metrics
    test_mase <- c(test_mase, mase_weekly)
    Ljung_Box_p_value <- c(Ljung_Box_p_value, lb_weekly)
    AIC <- c(AIC, AIC_weekly)
    seasonality <- c(seasonality, "weekly")
    category <- c(category, category_names[i])
  }
  tibble(product = product, category=category, method = method, seasonality = seasonality, test_mase = test_mase,  AIC = AIC, Ljung_Box_p_value = Ljung_Box_p_value)
}


#2. building STL model
stl_model <- function(train_series_daily, test_series_daily, train_series_weekly, test_series_weekly, item_names, category_names){
  #packages
  library(forecast)
  library(Metrics)
  #initializing vectors
  product <- rep(item_names,2)
  method <- rep("STL", 2*length(train_series_daily))
  seasonality <- c()
  test_mase <- c()
  Ljung_Box_p_value <- c()
  AIC <- c()
  category <- c()
  #daily data
  for (i in seq_along(train_series_daily)){
    model_daily <- stl(ts(train_series_daily[[i]],frequency=365), 'periodic')
    forecast_daily <- forecast(model_daily, h = 28)
    mase_daily <- mase(as.numeric(test_series_daily[[i]]), as.numeric(forecast_daily$mean))
    res_daily <- residuals(forecast_daily)
    lb_daily <- Box.test(res_daily, lag=10, type = "Lj")$p.value
    AIC_daily <- NA #AIC(model_daily)########
    #storing metrics
    test_mase <- c(test_mase, mase_daily)
    Ljung_Box_p_value <- c(Ljung_Box_p_value, lb_daily)
    AIC <- c(AIC, AIC_daily)
    seasonality <- c(seasonality, "daily")
  }
  #weekly data 
  for (i in seq_along(train_series_weekly)){
    model_weekly <- stl(train_series_weekly[[i]], 'periodic')
    forecast_weekly <- forecast(model_weekly, h = 28)
    mase_weekly <- mase(as.numeric(test_series_weekly[[i]]), as.numeric(forecast_weekly$mean))
    res_weekly <- residuals(forecast_weekly)
    lb_weekly <- Box.test(res_weekly, lag=14, type = "Lj")$p.value
    AIC_weekly <- NA #AIC(model_weekly)#########
    #storing metrics
    test_mase <- c(test_mase, mase_weekly)
    Ljung_Box_p_value <- c(Ljung_Box_p_value, lb_weekly)
    AIC <- c(AIC, AIC_weekly)
    seasonality <- c(seasonality, "weekly")
    category <- c(category, category_names[i])
  }
  category <- rep(category,2) #repeating because both daily and weekly data
  
  tibble(product = product, category=category, method = method, seasonality = seasonality, test_mase = test_mase,  AIC = AIC, Ljung_Box_p_value = Ljung_Box_p_value)
}



#3. building prophet model
prophet_model <- function(train_series_daily, test_series_daily, train_series_weekly, test_series_weekly, item_names, category_names){
  #packages
  library(forecast)
  library(Metrics)
  library(prophet)
  #initializing vectors
  product <- item_names
  method <- rep("Prophet", length(train_series_weekly))
  seasonality <- c()
  test_mase <- c()
  Ljung_Box_p_value <- c()
  AIC <- c()
  category <- c()
  #weekly data 
  for (i in seq_along(train_series_weekly)){
    model_weekly_df<- as.data.frame(cbind(
      "ds" = as.vector(seq(as.Date("2011-01-29"), as.Date("2016-03-27"), by="days")),
      "y" = as.vector(train_series_weekly[[i]])))
    model_weekly_df[['ds']] <- as.Date(model_weekly_df[['ds']], format='%Y-%m-%d')
    #fitting prophet onto data
    prophet_mod <- suppressWarnings(prophet(model_weekly_df))
    #making future dataframe
    future_df <- suppressWarnings(make_future_dataframe(prophet_mod, periods = 28))
    #creating forecast
    forecast_weekly <- suppressWarnings(predict(prophet_mod, future_df))
    #forecast_weekly <- forecast(model_weekly, h = 28)
    mase_weekly <- mase(as.numeric(test_series_weekly[[i]]), tail(forecast_weekly$yhat[], n=28))
    res_weekly <- head(forecast_weekly$yhat[],1885) - train_series_weekly[[i]]
    lb_weekly <- Box.test(res_weekly, lag=14, type = "Lj")$p.value
    AIC_weekly <- NA #AIC(model_weekly)
    #storing metrics
    test_mase <- c(test_mase, mase_weekly)
    Ljung_Box_p_value <- c(Ljung_Box_p_value, lb_weekly)
    AIC <- c(AIC, AIC_weekly)
    seasonality <- c(seasonality, "weekly")
    category <- c(category, category_names[i])
  }
  tibble(product = product, category=category, method = method, seasonality = seasonality, test_mase = test_mase, AIC = AIC, Ljung_Box_p_value = Ljung_Box_p_value)
}

```

```{r, echo =FALSE}
library(tidyverse)
# get a character vector of dept_ids
# takes a vector of item_ids and returns a vector of dept_ids of same length
generate_dept_ids <- function(item_ids) {
  # extract dept id from an item_id string
  extract_dept_id <- function(item_id) {
    substr(item_id, start = 1, stop = nchar(item_id) - 4)
  }
  # apply above function to vector of item_ids
  as.vector(apply(as.matrix(item_ids), MARGIN = 1, FUN = extract_dept_id))
}  



##########################################################################
# tidy_up()
##########################################################################

# get tidy data
# takes a vector of item_ids, state_ids, M5 sales training data, price data and calendar data
# and returns a tibble with sales data for the states specified aggregated/grouped by item_id, 
# with each item's time series stored as a column vector, and categorical variables of interest dummy-coded
tidy_up <- function(item_ids, state_ids, sales_dat, calendar_dat, prices_dat) {
  # filter sales and price data for items and states we want
  sales_dat <- sales_dat %>% filter(item_id %in% item_ids & state_id %in% state_ids)
  prices_dat <- prices_dat %>% filter(item_id %in% item_ids & substr(store_id,1,2) %in% state_ids) 
  
  # filter calendar for our date range
  calendar_dat <- calendar_dat[1:1913,]
  
  # check for any NAs outside of event variables, if any detected output warning
  if (any(is.na(calendar_dat %>% select(-(event_name_1:event_type_2)))) | 
      any(is.na(sales_dat)) | any(is.na(prices_dat))
      == TRUE) {warning("NAs detected. Recommended to impute or drop NA values before analysis")}
  
  # group by product in sales data, summing up sales
  suppressWarnings(sales_dat <- sales_dat %>% 
                     group_by(item_id) %>%
                     summarize_at(vars(d_1:d_1913), funs(sum)))
  
  # group by product in price data, averaging price
  prices_dat <- prices_dat %>% group_by(item_id, wm_yr_wk) %>% 
    summarize(sell_price = mean(sell_price))
  
  # transpose sales data so each series stored in a column
  sales_dat_copy <- sales_dat
  sales_dat <- t(as.data.frame(sales_dat_copy[,-1]))
  suppressWarnings(sales_dat <- as_tibble(sales_dat))
  colnames(sales_dat) <- item_ids
  
  # bind sales and calendar
  sales_dat <- bind_cols(sales_dat, calendar_dat)
  
  # extract item price series from sell_prices and join with sales data
  for (item in item_ids) {
    # to use for naming
    temp <- paste0('price_', item)
    
    # extract a product's price series
    item_price <- prices_dat %>% 
      filter(item_id == item) %>%
      ungroup() %>%
      select(wm_yr_wk, sell_price) %>%
      rename(!!temp := sell_price)
    
    # join with sales data
    sales_dat <- left_join(sales_dat, item_price, by = "wm_yr_wk")
  }
  
  # dummy code weekdays, with Saturday as the reference class
  sales_dat <- sales_dat %>% pivot_wider(names_from = weekday, values_from = wday)
  dummy_code <- function(x, na.rm = FALSE) ifelse(is.na(x), 0, 1)
  sales_dat <- sales_dat %>% mutate_at(vars(Saturday:Friday), funs(dummy_code))
  sales_dat <- sales_dat %>% select(-(Saturday))
  message("Week days dummy-coded with Saturday as the reference class.")
  
  # dummy code months, with January as the reference class
  months <- c('February','March','April','May','June','July','August','September','October','November','December')
  for (i in 1:length(months)) {
    month_dummy <- as.numeric(sales_dat$month == i+1)
    sales_dat[months[i]] <- month_dummy
  }
  message("Months dummy-coded with January as the reference class.")
  
  # dummy code event types
  sales_dat <- sales_dat %>% mutate(Sporting = if_else(event_type_1 == 'Sporting' | event_type_2 == 'Sporting',1,0, missing = 0),
                                    Cultural = if_else(event_type_1 == 'Cultural' | event_type_2 == 'Cultural',1,0, missing = 0),
                                    National = if_else(event_type_1 == 'National' | event_type_2 == 'National',1,0, missing = 0),
                                    Religious = if_else(event_type_1 == 'Religious' | event_type_2 == 'Religious',1,0, missing = 0))
  message("Event types dummy-coded.")
  
  # create trend variable
  sales_dat$trend <- seq(1, nrow(sales_dat))
  message("Created trend variable.")
  
  # drop variables we've created dummies for and other variables we don't care for
  snaps <- paste0("snap_", state_ids)
  no_snaps <- c("snap_TX", "snap_WI", "snap_CA")[!(c("snap_TX", "snap_WI", "snap_CA") %in% snaps)]
  sales_dat <- sales_dat %>% select(-d,-(all_of(no_snaps)), -month, -(event_name_1:event_type_2))
  message("Dropped snap variables for states not specified.")
  message("Dropped event name column and event types columns (since they've been dummied).")
  
  # reorder for aesthetics
  sales_dat <- sales_dat %>% select(trend, date, year, (all_of(item_ids)),
                                    (paste0('price_',item_ids[1]):paste0('price_',item_ids[length(items)])),
                                    (paste0('snap_',state_ids[1]):paste0('snap_',state_ids[length(states)])),
                                    (Sporting:Religious), (Sunday:Friday), (February:December))
  
  # return sales data
  sales_dat
}


##########################################################################
# extract_train_weekly()
##########################################################################

# functions to get training and test data
# takes a vector of item_ids and tidy sales data
# returns a list, with each element being a sales time series object
# train are observations 1:1885, test are observations 1886:1913
# weekly frequency = 7, daily frequency = 1
# naming convention for each ts is "train/test_weekly/daily_ITEM_ID", 
# e.g. "train_weekly_FOODS_2_197" is the training series with weekly seasonality for item_id FOODS_2_197
# note: when indexing into these lists (while in a loop, for example), I recommend double square brackets, i.e. [[]]
# because list[[i]] returns the ts object itself, while list[i] returns the list with only the ts object i inside
extract_train_weekly <- function(item_ids, tidy_sales_dat) {
  # create vector of names for time series
  series_names <- paste0("train_weekly_", item_ids)
  # start specification for ts object
  startW <- as.numeric(strftime(tidy_sales_dat$date[1], format = "%W"))
  startD <- as.numeric(strftime(tidy_sales_dat$date[1] + 1, format =" %w")) 
  
  # iterate along item_ids and extract training time series for each
  # assigning it to the names defined earlier
  for (i in seq_along(item_ids)) {
    assign(series_names[i],
           ts(eval(pull(tidy_sales_dat, item_ids[i])[1:1885]), frequency = 7, start = c(startW, startD)),
    )
    
  }
  # some parsing gymnastics to create a list of the variables created in the loop
  to_parse <- paste("list(", paste(eval(parse(text = "series_names")), collapse = ", "), ")")
  
  # assign series names to the list of time series
  return_list <- eval(parse(text = to_parse))
  names(return_list) <- series_names
  
  return_list
}

##########################################################################
# extract_train_daily()
##########################################################################

extract_train_daily <- function(item_ids, tidy_sales_dat) {
  # create vector of names for time series
  series_names <- paste0("train_daily_", item_ids)
  # start specification for ts object
  startD <- as.numeric(strftime(tidy_sales_dat$date[1], format = "%j"))
  
  # iterate along item_ids and extract training time series for each
  # assigning it to the names defined earlier
  for (i in seq_along(item_ids)) {
    assign(series_names[i],
           ts(eval(pull(tidy_sales_dat, item_ids[i])[1:1885]), frequency = 1, start = startD),
    )
    
  }
  # some parsing gymnastics to create a list of the variables created in the loop
  to_parse <- paste("list(", paste(eval(parse(text = "series_names")), collapse = ", "), ")")
  
  # assign series names to the list of time series
  return_list <- eval(parse(text = to_parse))
  names(return_list) <- series_names
  
  return_list
}

##########################################################################
# extract_test_weekly()
##########################################################################

extract_test_weekly <- function(item_ids, tidy_sales_dat) {
  # create vector of names for time series
  series_names <- paste0("test_weekly_", item_ids)
  # start specification for ts object
  startW <- as.numeric(strftime(tidy_sales_dat$date[1886], format = "%W"))
  startD <- as.numeric(strftime(tidy_sales_dat$date[1886] + 1, format =" %w")) 
  
  # iterate along item_ids and extract training time series for each
  # assigning it to the names defined earlier
  for (i in seq_along(item_ids)) {
    assign(series_names[i],
           ts(eval(pull(tidy_sales_dat, item_ids[i])[1886:1913]), frequency = 7, start = c(startW, startD)),
    )
    
  }
  # some parsing gymnastics to create a list of the variables created in the loop
  to_parse <- paste("list(", paste(eval(parse(text = "series_names")), collapse = ", "), ")")
  
  # assign series names to the list of time series
  return_list <- eval(parse(text = to_parse))
  names(return_list) <- series_names
  
  return_list
}

##########################################################################
# extract_test_daily()
##########################################################################

extract_test_daily <- function(item_ids, tidy_sales_dat) {
  # create vector of names for time series
  series_names <- paste0("test_daily_", item_ids)
  # start specification for ts object
  startD <- as.numeric(strftime(tidy_sales_dat$date[1886], format = "%j"))
  
  # iterate along item_ids and extract training time series for each
  # assigning it to the names defined earlier
  for (i in seq_along(item_ids)) {
    assign(series_names[i],
           ts(eval(pull(tidy_sales_dat, item_ids[i])[1886:1913]), frequency = 1, start = startD),
    )
    
  }
  # some parsing gymnastics to create a list of the variables created in the loop
  to_parse <- paste("list(", paste(eval(parse(text = "series_names")), collapse = ", "), ")")
  
  # assign series names to the list of time series
  return_list <- eval(parse(text = to_parse))
  names(return_list) <- series_names
  
  return_list
}

##########################################################################
# extract_train_xreg()
##########################################################################
# get training and test xreg matrices
# external regressors include: prices for all item_ids specified, event type dummies, snap dummies for state_ids specified
# takes a vector of item_ids, a vector of state_ids, and tidy sales data
# returns a matrix of external regressors
extract_train_xreg <- function(item_ids, state_ids, tidy_sales_dat) {
  snaps <- paste0("snap_", state_ids)
  prices <- paste0("price_", item_ids)
  
  return_mat <- tidy_sales_dat %>% select(all_of(prices), all_of(snaps), (Sporting:Religious))
  as.matrix(return_mat)[1:1885, -c(9, 10, 19, 22, 23, 24, 25)]
}

##########################################################################
# extract_test_xreg()
##########################################################################
extract_test_xreg <- function(item_ids, state_ids, tidy_sales_dat) {
  snaps <- paste0("snap_", state_ids)
  prices <- paste0("price_", item_ids)
  
  return_mat <- tidy_sales_dat %>% select(all_of(prices), all_of(snaps), (Sporting:Religious))
  as.matrix(return_mat)[1886:1913, -c(9, 10, 19, 22, 23, 24, 25)]
}

```



### Holt Winters results
```{r}
Holt_Winters_res <- Holt_Winters_model(train_series_daily, test_series_daily, train_series_weekly, test_series_weekly, item_names, category_names)
head(Holt_Winters_res)
```

#STL Results:
```{r}
STL_res <- stl_model(train_series_daily, test_series_daily, train_series_weekly, test_series_weekly, item_names, category_names)
head(STL_res)
```

# Prophet Results
```{r}
Prophet_res <- suppressWarnings(prophet_model(train_series_daily, test_series_daily, train_series_weekly, test_series_weekly, item_names, category_names))
head(Prophet_res)
```

#TBATS
```{r}
TBATS_res <- suppressWarnings(TBATS_model(train_series_daily, test_series_daily, train_series_weekly, test_series_weekly, item_names, category_names))
head(TBATS_res)
```


# ARMA-GARCH models
```{r}
daily_arma_garch_results <- suppressWarnings(arma_garch(train_series_daily, test_series_daily, item_names, category_names))
weekly_arma_garch_results <- suppressWarnings(arma_garch(train_series_weekly, test_series_weekly, item_names, category_names))
#compiling results
arma_garch_results <- bind_rows(daily_arma_garch_results, weekly_arma_garch_results)

arma_garch_results$method ="ARMA-GARCH"

arma_garch_results

```

# neural nets
```{r}
daily_neural_net_results <- neural_net(train_series_daily, test_series_daily, item_names, category_names)
weekly_neural_net_results <- neural_net(train_series_weekly, test_series_weekly, item_names, category_names)
#compiling results
neural_net_results <- bind_rows(daily_neural_net_results, weekly_neural_net_results)

neural_net_results$method <- "NNAR"

head(neural_net_results)
```

# hierarchical models
```{r}
hierarchical_results <- read_csv('/Users/markroberts/Desktop/Time Series/FinalProject/hierarchical_results_yk.csv')
head(hierarchical_results)
```

#Remaining Model Results
```{r}
beals_results <- read_csv('/Users/markroberts/Desktop/Time Series/FinalProject/beals_output.csv')
head(beals_results)
```

# Compiling Results
```{r}
results <- bind_rows(Holt_Winters_res[,c(1,2,3,4,5,7)], STL_res[,c(1,2,3,4,5,7)], Prophet_res[,c(1,2,3,4,5,7)], TBATS_res[,c(1,2,3,4,5,7)], arma_garch_results[,c(1,2,3,4,5,7)],neural_net_results[,c(1,2,3,4,5,7)],hierarchical_results[,c(1,2,3,4,5,7)], beals_results[,c(1,2,3,4,5,7)])
head(results)
```


plotting mase scores- individual items
```{r}
ggplot(data=results, mapping = aes(x=method, y=test_mase, colour = product, group=interaction(product, seasonality))) +
  geom_line(lwd=1.25) +
  xlab("Model Type") +
  ylab("MASE score on test data") +
  theme(axis.text.x = element_text(angle = 90)) +
  ggtitle("MASE scores for Methods by Item Type") +
  scale_color_manual(values = pal, name = 'Category') 
```

plotting mase scores- individual items, colored by categories
```{r}
ggplot(data=results, mapping = aes(x=method, y=test_mase, colour = category, group=interaction(product, seasonality))) +
  geom_line(lwd=1.25) +
  xlab("Model Type") +
  ylab("MASE score on test data") +
  theme(axis.text.x = element_text(angle = 45)) +
  ggtitle("MASE scores for Methods by Item Type") +
  scale_color_manual(values = four_colors, name = 'Category') 
```

Grouping by category MASE
```{r}
results_grouped_mace <- results %>% 
  group_by(method, category) %>%
  summarize(mean_mase = mean(test_mase, na.rm=TRUE))
head(results_grouped_mace)
```

plotting MASE grouped by category
```{r}
ggplot(data=results_grouped_mace, mapping = aes(x=method, y=mean_mase, colour = category, group = category)) +
  geom_line(lwd=1.5) +
  xlab("Model Type") +
  ylab("MASE score on test data") +
  ggtitle("MASE scores for Methods by Category") +
  theme_stata() + 
  scale_colour_stata()+
  theme(axis.text.x = element_text(angle = 45))
```


Grouping MASE overall
```{r}
results_grouped_all_mace <-
  results_grouped_mace %>% 
  group_by(method) %>%
  summarize(mean_mase = mean(mean_mase, na.rm=TRUE))

head(results_grouped_all_mace)
```

plotting overall MASE avg score
```{r}
ggplot(data=results_grouped_all_mace, mapping = aes(x=method, y=mean_mase, group=category)) +
  geom_line(lwd=1.5, color=single_color) +
  xlab("Model Type") +
  ylab("MASE score on test data") +
  ggtitle("MASE scores for Methods Overall Average") +
  theme_stata() + 
  scale_colour_stata() +
  theme(axis.text.x = element_text(angle = 45))

```

```{r}
ggplot(data=results_grouped_all_mace, mapping = aes(x=reorder(method,-(mean_mase) ), y=(mean_mase), group = category)) + 
theme(axis.text.x = element_text(angle = 90)) +
geom_bar(stat= 'identity', fill = single_color) +
ylab("MASE Score") +
xlab("Model Name") +
ggtitle("MASE Scores by Model Type") +
coord_flip() +
theme_stata() + 
scale_colour_stata() +
theme(axis.text.y = element_text(angle = 0)) 
```



#Ljung Box P-value



plotting pvalue scores- individually colored
```{r}
ggplot(data=results, mapping = aes(x=method, y=Ljung_Box_p_value,color = product, group=interaction(product, seasonality)))+ 
  geom_line(lwd=1.25) +
  ggtitle("Ljung Box p-value scores for Methods by Item Type") +
  xlab("Model Type") +
  theme(axis.text.x = element_text(angle = 45)) +
  ylab("Ljung Box p-value") +
  scale_color_manual(values = pal, name = 'Item') 
```

plotting pvalue scores- colored by category
```{r}
ggplot(data=results, mapping = aes(x=method, y=Ljung_Box_p_value,color = category, group=interaction(product, seasonality)))+ 
  geom_line(lwd=1.5) +
  ggtitle("Ljung Box p-value scores for Methods by Item Type") +
  xlab("Model Type") +
  theme(axis.text.x = element_text(angle = 45)) +
  ylab("Ljung Box p-value") +
  scale_color_manual(values = four_colors, name = 'Category')
```

Grouping by category
```{r}
results_grouped_pval <- results %>% 
  group_by(method, category) %>%
  summarize(mean_ljung_pvalue = mean(Ljung_Box_p_value, na.rm=TRUE))

results_grouped_pval
```


plotting- grouped by category
```{r}
ggplot(data=results_grouped_pval, mapping = aes(x=method, y=mean_ljung_pvalue, colour = category, group = category)) +
  geom_line(lwd=1.5) +
  xlab("Model Type") +
  ylab("Ljung Box Test P-value") +
  ggtitle("Ljung Box P-Values for Methods by Category") +
  #geom_line(aes(y=.05, colour = "Significant Level"), linetype = "dashed") +
  theme_stata() + 
  scale_colour_stata() +
  theme(axis.text.x = element_text(angle = 45))
```

Grouping pvalue overall
```{r}
results_grouped_all_pvalue <-
  results_grouped_pval %>% 
  group_by(method) %>%
  summarize(mean_ljung_pvalue = mean(mean_ljung_pvalue, na.rm=TRUE))

head(results_grouped_all_pvalue)
```

plotting overall pvalue avg score
```{r}
ggplot(data=results_grouped_all_pvalue, mapping = aes(x=method, y=mean_ljung_pvalue, group=category)) +
  geom_line(lwd=1.25, color = single_color) +
  xlab("Model Type") +
  ylab("Pvalue on test data") +
  ggtitle("Ljung Box P-values for Methods Overall Average") +
  theme_stata() + 
  scale_colour_stata() +
  theme(axis.text.x = element_text(angle = 45))


```
barplot version
```{r}
ggplot(data=results_grouped_all_pvalue, mapping = aes(x=reorder(method,(mean_ljung_pvalue) ), y=(mean_ljung_pvalue), group = category)) + 
geom_bar(stat= 'identity', fill = single_color) +
ylab("Ljung Box Test P-value") +
xlab("Model Name") +
ggtitle("Ljung Box P-Value by Model Type") +
coord_flip() +
theme_stata() + 
scale_colour_stata() +
theme(axis.text.y = element_text(angle = 0))
```


#Combining overall Average plots
```{r}
overall_results_avg <- as_tibble(cbind("Method" = results_grouped_all_mace$method, 
                             "MASE" = results_grouped_all_mace$mean_mase, 
                             "P-Value"= results_grouped_all_pvalue$mean_ljung_pvalue))
overall_results_avg <- overall_results_avg %>% 
  mutate(`MASE` = as.numeric(MASE), `P-Value` = as.numeric(`P-Value`))

#melting results for plotting
overall_melted <- melt(data = overall_results_avg, id.vars = "Method", measure.var = c("MASE", "P-Value"))
```

Metric Overall Comparision
```{r}
ggplot(data = overall_melted, mapping = aes(x=Method, y =value, color = variable, group = variable )) +
  geom_line(lwd=1.5) +
  ylab("Value") +
  xlab("Model Type") +
  ggtitle("Overall Model Performance") + 
  theme_stata() + 
  scale_colour_stata() +
  theme(axis.text.x = element_text(angle =45))
```

# Computing Score Metric
```{r}
overall_results_avg$total_score <- (1/overall_results_avg$MASE) + overall_results_avg$`P-Value` #can add weights here, edit scoring
overall_results_avg
```


Plotting New "Score" Metric 
```{r}
ggplot(data=overall_results_avg, mapping = aes(x=Method, y=total_score, group = category)) + #largest score = best model
geom_line(lwd=2, col = single_color) +
ggtitle("Overall Scoring for all Models") +
theme_stata() + 
scale_colour_stata() +
theme(axis.text.x = element_text(angle = 45))

```

barplot version
```{r}
ggplot(data=overall_results_avg, mapping = aes(x=reorder(Method,(total_score) ), y=(total_score), group = category)) + 
geom_bar(stat= 'identity', fill = single_color) +
ylab("Computed Score") +
xlab("Model Type") +
ggtitle("Overall Computed Score for all Models") +
coord_flip() +
theme_stata() + 
scale_colour_stata() +
theme(axis.text.y = element_text(angle = 0))
```







